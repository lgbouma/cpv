"""
Tools when interpolating against isochrones.

| get_Feiden2016
| get_PARSEC
| nn_PARSEC_interpolator
| PARSEC_interpolator
"""
import os
from os.path import join
from glob import glob
from complexrotators.paths import DATADIR
import pandas as pd, numpy as np, matplotlib.pyplot as plt
from astropy import units as u, constants as c

from scipy.interpolate import LinearNDInterpolator

def get_Feiden2016(subtype='mag'):
    """
    Get the Feiden+2016 magnetic models, which span ~1 to 50 Myr.
    """
    isodir = join(DATADIR, 'models', 'Feiden_2016_iso', subtype)
    isopaths = glob(join(isodir, 'dmestar*.iso'))

    ages_myr = [
        os.path.basename(i).split("_")[1].replace('myr','').lstrip('0')
        for i in isopaths
    ]

    dfs = []
    for age_myr, isopath in zip(ages_myr, isopaths):
        _df = pd.read_csv(
            isopath, comment='#',
            names='mass logTeff logg logL logR A(Li) Mconv,env'.split(" "),
            delim_whitespace=True
        )
        _df['age'] = age_myr
        dfs.append(_df)
    df = pd.concat(dfs)

    return df


def get_PARSEC():
    """
    1 to 200 myr, linearly spaced by 1 myr; all available masses.  solar metallicity.

    # File generated by CMD 3.7 (http://stev.oapd.inaf.it/cmd) on Sat Jun 24 05:06:03 CEST 2023
    # isochrones based on PARSEC release v1.2S +  COLIBRI S_37 + S_35 + PR16
    # Basic references:
    # Bressan et al. (2012), MNRAS, 427, 127 +
    # Chen et al. (2014, 2015), MNRAS, 444, 2525 + MNRAS, 452, 1068 +
    # Tang et al. (2014), MNRAS, 445, 4287 +
    # Marigo et al. (2017), ApJ, 835, 77 +
    # Pastorelli al. (2019), MNRAS, 485, 5666 +
    # Pastorelli al. (2020), MNRAS, in press
    # Thermal pulse cycles included
    # On RGB, assumed Reimers mass loss with efficiency eta=0.2
    # LPV periods and growth rates added cf. Trabucchi et al. (2019)
    # but fundamental-mode LPV periods are from Trabucchi et al. (2021)
    # Photometric system: <i>UBVRIJHK</i> (cf. Maiz-Apellaniz 2006 + Bessell 1990)
    # Using YBC version of bolometric corrections as in Chen et al. (2019)
    # O-rich circumstellar dpmod60alox40 dust from Groenewegen (2006)
    # C-rich circumstellar AMCSIC15 dust from Groenewegen (2006)
    # IMF: Kroupa (2001, 2002) + Kroupa et al. (2013) canonical
    # two-part-power law IMF corrected for unresolved binaries
    """

    isopath = join(DATADIR, 'models', 'PARSEC_v1.2', "output101431780335.dat")

    df = pd.read_csv(isopath, delim_whitespace=True, comment='#')

    L = 10**(np.array(df.logL)) * u.Lsun
    Teff = 10**(np.array(df.logTe)) * u.K
    # σT^4 = L / (4πR^2)
    # R^2 = L / (4 * π * σT^4 )
    Rstar = np.sqrt(
        L / (4 * np.pi * c.sigma_sb * Teff**4)
    ).to(u.Rsun)

    df['Teff'] = np.array(Teff.value)
    df['Rstar'] = np.array(Rstar.value)
    df['logRstar'] = np.log10(np.array(Rstar.value))
    df['age'] = 10**(df.logAge) / (1e6)

    return df


def nn_PARSEC_interpolator(rstar, teff, age, rstar_err, teff_err, age_err):
    # age: myr

    # 1 to 200 myr, linearly spaced by 1 myr; all available masses.  solar metallicity.
    # get and clean 
    df = get_PARSEC()
    sel = (
        (df.Mass < 1.5)
        &
        (df.logRstar > -4)
    )
    df = df[sel] # < 2 solar

    # calculate distance!
    dist = np.sqrt(
    np.array( ( (df['Rstar'] - rstar) / rstar_err )**2 )
    +
    np.array( ( (df['Teff'] - teff) / teff_err )**2 )
    +
    np.array( ( (df['age'] - age) / age_err )**2 )
    )
    df['dist_median'] = dist

    varyparams = 'Rstar Teff age '
    varyvals = [rstar_err, teff_err, age_err]

    for varyparam, val in zip(varyparams.split(), varyvals):
        if varyparam == 'Rstar':
            _rstar = rstar + rstar_err
            _teff = teff
            _age_myr = age
        elif varyparam == 'Teff':
            _rstar = rstar
            _teff = teff + teff_err
            _age_myr = age
        elif varyparam == 'age':
            _rstar = rstar
            _teff = teff
            _age_myr = age + age_err
        dist = np.sqrt(
             np.array( ( (df['Rstar'] - _rstar) / rstar_err )**2 )
             +
             np.array( ( (df['Teff'] - _teff) / teff_err )**2 )
             +
             np.array( ( (df['age'] - _age_myr) / age_err )**2 )
        )
        df[f'dist_p1sig_{varyparam}'] = dist

    for varyparam, val in zip(varyparams.split(), varyvals):
        if varyparam == 'Rstar':
            _rstar = rstar - rstar_err
            _teff = teff
            _age_myr = age
        elif varyparam == 'Teff':
            _rstar = rstar
            _teff = teff - teff_err
            _age_myr = age
        elif varyparam == 'age':
            _rstar = rstar
            _teff = teff
            _age_myr = age - age_err
        dist = np.sqrt(
             np.array( ( (df['Rstar'] - _rstar) / rstar_err )**2 )
             +
             np.array( ( (df['Teff'] - _teff) / teff_err )**2 )
             +
             np.array( ( (df['age'] - _age_myr) / age_err )**2 )
        )
        df[f'dist_m1sig_{varyparam}'] = dist


    outparams = 'Mass logg Rstar age Teff dist_median'.split()

    bestdict = {
        v: float(df.sort_values(by='dist_median').head(n=1)[v]) for v in outparams
    }
    bestdict_p1sig = {
        v+"_p1sig_"+vp: float(df.sort_values(by=f'dist_p1sig_{vp}').head(n=1)[v]) for v in
        outparams for vp in varyparams.split()
    }
    bestdict_m1sig = {
        v+"_m1sig_"+vp: float(df.sort_values(by=f'dist_m1sig_{vp}').head(n=1)[v]) for v in
        outparams for vp in varyparams.split()
    }

    outdict = {}

    rfn = lambda x : np.round(x, 3)

    for k, v in bestdict.items():

        # get the perr statistical uncertainty on the parameter k
        p1sig_options, m1sig_options = [], []
        for vp in varyparams.split():
            p1sig_options.append(bestdict_p1sig[k+"_p1sig_"+vp])
            m1sig_options.append(bestdict_m1sig[k+"_m1sig_"+vp])

        p1sig = np.max(np.abs(np.array(p1sig_options) - v))
        m1sig = np.max(np.abs(np.array(m1sig_options) - v))

        if k == 'Mass':
            if p1sig / v < 0.05:
                p1sig = 0.05*v
            if p1sig / v > 0.3333:
                p1sig = 0.3333*v
            if m1sig / v < 0.05:
                m1sig = 0.05*v
            if m1sig / v > 0.3333:
                m1sig = 0.3333*v

        outdict[k] = (rfn(v), rfn(p1sig), rfn(m1sig))

    return outdict



def PARSEC_interpolator(rstar, teff, age_myr):
    """
    Interpolate against the PARSEC models.

    Given a star's Rstar, Teff, and age, return Mstar, logg, rstar, age, teff,
    and dist_metric through linear (N-D) interpolation.

    (Optional: incorporate uncertainties by repeating the calsl, but on +1sigma
    rstar, +1sigma Teff, +1sigma age, etc.)
    """

    raise NotImplementedError("preliminary tests below did not finish!")

    in_logRstar = np.log10(rstar) # solar
    in_logTe = np.log10(teff) # K
    in_logAge = np.log10(age_myr*1e6) # age given in myr

    df = get_PARSEC()
    sel = (
        (df.Mass < 1.5)
        &
        (df.logRstar > -4)
    )
    df = df[sel] # < 2 solar

    knowncols = 'logAge logTe logRstar'.split()
    targetcol = 'Mass'

    # given model "m_" logAge, logTe, logRstar, want model Mass.
    m_logAge = np.array(df['logAge'])
    m_logTe = np.array(df['logTe'])
    m_logRstar = np.array(df['logRstar'])

    m_Mass = np.array(df['Mass'])

    # define a separate linearly spaced Model "M_" grid
    M_logAge = np.linspace(min(m_logAge), max(m_logAge), 10)
    M_logTe = np.linspace(min(m_logTe), max(m_logTe), 11)
    M_logRstar = np.linspace(min(m_logRstar), max(m_logRstar), 12)

    M_logAge, M_logTe, M_logRstar = np.meshgrid(M_logAge, M_logTe, M_logRstar)

    interp = LinearNDInterpolator(
        list(zip(m_logAge, m_logTe, m_logRstar)), m_Mass
    )

    #FIXME TODO need to meshgrid somehwere!!
    M_Mass = interp(M_logAge, M_logTe, M_logRstar)

    import IPython; IPython.embed()
    plt.pcolormesh(M_logAge, M_logRstar, M_Mass, shading='auto')
    plt.plot(m_logAge, m_logRstar, m_Mass, label='input points')
    plt.legend()
    plt.colorbar()
    plt.savefig('temp.png', dpi=350)
